[[34m2023-05-13 13:52:43[0m] Experiment directory created at ~/results/retrain_irazor/avazu/001-retrain_irazor
[[34m2023-05-13 13:52:43[0m] Batchsize: 256
[[34m2023-05-13 13:52:50[0m] From /home/ubuntu/miniconda3/envs/irazor/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
[[34m2023-05-13 13:52:51[0m] From /home/ubuntu/miniconda3/envs/irazor/lib/python3.11/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
[[34m2023-05-13 13:52:51[0m] total batches: 126350	batch per epoch: 12635
[[34m2023-05-13 13:52:51[0m] new iteration
[[34m2023-05-13 13:53:08[0m] elapsed : 0:00:16, ETA : 0:33:25
[[34m2023-05-13 13:53:08[0m] epoch 1 / 10, batch 1000 / 12635, global_step = 1000, learning_rate = 1.000000e-02, loss = 0.439764, l2 = 0.182616, auc = 0.665648
[[34m2023-05-13 13:53:24[0m] elapsed : 0:00:32, ETA : 0:33:09
[[34m2023-05-13 13:53:24[0m] epoch 1 / 10, batch 2000 / 12635, global_step = 2000, learning_rate = 1.000000e-02, loss = 0.403309, l2 = 0.049449, auc = 0.737083
[[34m2023-05-13 13:53:39[0m] elapsed : 0:00:47, ETA : 0:32:12
[[34m2023-05-13 13:53:39[0m] epoch 1 / 10, batch 3000 / 12635, global_step = 3000, learning_rate = 1.000000e-02, loss = 0.398698, l2 = 0.022060, auc = 0.745051
[[34m2023-05-13 13:53:54[0m] elapsed : 0:01:03, ETA : 0:32:07
[[34m2023-05-13 13:53:54[0m] epoch 1 / 10, batch 4000 / 12635, global_step = 4000, learning_rate = 1.000000e-02, loss = 0.395755, l2 = 0.012193, auc = 0.749869
[[34m2023-05-13 13:54:10[0m] elapsed : 0:01:18, ETA : 0:31:33
[[34m2023-05-13 13:54:10[0m] epoch 1 / 10, batch 5000 / 12635, global_step = 5000, learning_rate = 1.000000e-02, loss = 0.395236, l2 = 0.007999, auc = 0.749924
[[34m2023-05-13 13:54:25[0m] elapsed : 0:01:33, ETA : 0:31:05
[[34m2023-05-13 13:54:25[0m] epoch 1 / 10, batch 6000 / 12635, global_step = 6000, learning_rate = 1.000000e-02, loss = 0.394786, l2 = 0.005983, auc = 0.752523
[[34m2023-05-13 13:54:40[0m] elapsed : 0:01:48, ETA : 0:30:41
[[34m2023-05-13 13:54:40[0m] epoch 1 / 10, batch 7000 / 12635, global_step = 7000, learning_rate = 1.000000e-02, loss = 0.393880, l2 = 0.004868, auc = 0.752857
[[34m2023-05-13 13:55:04[0m] elapsed : 0:02:12, ETA : 0:32:32
[[34m2023-05-13 13:55:04[0m] epoch 1 / 10, batch 8000 / 12635, global_step = 8000, learning_rate = 1.000000e-02, loss = 0.393482, l2 = 0.004275, auc = 0.755796
[[34m2023-05-13 13:55:39[0m] elapsed : 0:02:47, ETA : 0:36:17
[[34m2023-05-13 13:55:39[0m] epoch 1 / 10, batch 9000 / 12635, global_step = 9000, learning_rate = 1.000000e-02, loss = 0.391974, l2 = 0.003905, auc = 0.757116
[[34m2023-05-13 13:56:13[0m] elapsed : 0:03:21, ETA : 0:38:58
[[34m2023-05-13 13:56:13[0m] epoch 1 / 10, batch 10000 / 12635, global_step = 10000, learning_rate = 1.000000e-02, loss = 0.390302, l2 = 0.003679, auc = 0.758211
[[34m2023-05-13 13:56:48[0m] elapsed : 0:03:56, ETA : 0:41:14
[[34m2023-05-13 13:56:48[0m] epoch 1 / 10, batch 11000 / 12635, global_step = 11000, learning_rate = 1.000000e-02, loss = 0.390730, l2 = 0.003472, auc = 0.758463
[[34m2023-05-13 13:57:22[0m] elapsed : 0:04:30, ETA : 0:42:52
[[34m2023-05-13 13:57:22[0m] epoch 1 / 10, batch 12000 / 12635, global_step = 12000, learning_rate = 1.000000e-02, loss = 0.389177, l2 = 0.003352, auc = 0.761679
[[34m2023-05-13 13:57:44[0m] running test...
[[34m2023-05-13 13:57:49[0m] evaluated batches: 1000, 0:00:04
[[34m2023-05-13 13:57:53[0m] evaluated batches: 2000, 0:00:04
[[34m2023-05-13 13:57:57[0m] evaluated batches: 3000, 0:00:04
[[34m2023-05-13 13:58:01[0m] evaluated batches: 4000, 0:00:04
[[34m2023-05-13 13:58:05[0m] evaluated batches: 5000, 0:00:04
[[34m2023-05-13 13:58:10[0m] evaluated batches: 6000, 0:00:04
[[34m2023-05-13 13:58:14[0m] evaluated batches: 7000, 0:00:04
[[34m2023-05-13 13:58:18[0m] evaluated batches: 8000, 0:00:04
[[34m2023-05-13 13:58:23[0m] evaluated batches: 9000, 0:00:04
[[34m2023-05-13 13:58:27[0m] evaluated batches: 10000, 0:00:04
[[34m2023-05-13 13:58:31[0m] evaluated batches: 11000, 0:00:04
[[34m2023-05-13 13:58:35[0m] evaluated batches: 12000, 0:00:04
[[34m2023-05-13 13:58:39[0m] evaluated batches: 13000, 0:00:04
[[34m2023-05-13 13:58:43[0m] evaluated batches: 14000, 0:00:04
[[34m2023-05-13 13:58:47[0m] evaluated batches: 15000, 0:00:04
[[34m2023-05-13 13:58:52[0m] evaluated batches: 16000, 0:00:04
[[34m2023-05-13 13:58:56[0m] evaluated batches: 17000, 0:00:04
[[34m2023-05-13 13:59:00[0m] evaluated batches: 18000, 0:00:04
[[34m2023-05-13 13:59:04[0m] evaluated batches: 19000, 0:00:04
[[34m2023-05-13 13:59:09[0m] evaluated batches: 20000, 0:00:04
[[34m2023-05-13 13:59:13[0m] evaluated batches: 21000, 0:00:04
[[34m2023-05-13 13:59:17[0m] evaluated batches: 22000, 0:00:04
[[34m2023-05-13 13:59:21[0m] evaluated batches: 23000, 0:00:04
[[34m2023-05-13 13:59:25[0m] evaluated batches: 24000, 0:00:04
[[34m2023-05-13 13:59:30[0m] evaluated batches: 25000, 0:00:04
[[34m2023-05-13 13:59:34[0m] evaluated batches: 26000, 0:00:04
[[34m2023-05-13 13:59:38[0m] evaluated batches: 27000, 0:00:04
[[34m2023-05-13 13:59:42[0m] evaluated batches: 28000, 0:00:04
[[34m2023-05-13 13:59:46[0m] evaluated batches: 29000, 0:00:04
[[34m2023-05-13 13:59:51[0m] evaluated batches: 30000, 0:00:04
[[34m2023-05-13 13:59:55[0m] evaluated batches: 31000, 0:00:04
[[34m2023-05-13 14:00:01[0m] test loss = 0.390991, test auc = 0.761177
[[34m2023-05-13 14:00:01[0m] evaluated time: 0:02:17
[[34m2023-05-13 14:00:01[0m] analyse_structure
